# BURIED TREASURE:  Using Natural Language Processing to mine text

from __future__ import unicode_literals, print_function

import glob  # list only some files, depending on the file pattern
import re  # import regular expression operation

import nltk
from nltk import word_tokenize
from nltk.chunk import *
from nltk.chunk.regexp import *
from nltk.chunk.util import *
from nltk.collocations import *
from nltk.tag.stanford import StanfordNERTagger
from nltk.tokenize import PunktSentenceTokenizer

_stanford_url = 'http://nlp.stanford.edu/software/*'
# _stanford_url = 'http://nlp.stanford.edu/software/tokenizer.shtml'

st = StanfordNERTagger('./Desktop/Stanford/stanford-ner-2015-12-09/classifiers/english.muc.7class.distsim.crf.ser.gz',
                       './Desktop/Stanford/stanford-ner-2015-12-09/stanford-ner.jar',
                       encoding='utf-8')

EMAIL_REGEX = r'[\w\.-]+@[\w\.-]+'
PHONE_REGEX = r'\d{3}[-\.\s]??\d{3}[-\.\s]??\d{4}|\(\d{3}\)\s*\d{3}[-\.\s]??\d{4}|\d{3}[-\.\s]??\d{4}'


def find_sentences_with_contact_details(text):
    emails = []
    starting_tokenizer = PunktSentenceTokenizer(text)
    tokenized_text = starting_tokenizer.tokenize(text)
    for sentence in tokenized_text:
        match = re.findall(EMAIL_REGEX + r'|' + PHONE_REGEX, sentence)
        if match:
            emails.append((match[0], sentence))
    return emails


def find_proper_nouns(sentence):
    proper_nouns = []
    wanted_tags = ['NNP']

    words = nltk.word_tokenize(sentence)
    tagged = nltk.pos_tag(words)
    for word, tag in tagged:
        if tag in wanted_tags:
            proper_nouns.append(word)
    return proper_nouns


def find_named_entities(text):
    named_entities = set()
    wanted_tags = ['PERSON', 'LOCATION', 'ORGANISATION']
    tokenized_text = word_tokenize(text)
    classified_text = st.tag(tokenized_text)
    for word, tag in classified_text:
        if tag in wanted_tags:
            named_entities.add(word)
    return named_entities


# Read all the texts from given folder
text_1 = ''
for filename in glob.glob('./Desktop/Texts/*'):
    with open(filename) as file:
        text_1 += file.read()

emails_and_sentences = find_sentences_with_contact_details(text_1)
named_entities = find_named_entities(text_1)

for email, sentence in emails_and_sentences:
    nouns = find_proper_nouns(sentence)
    nouns = [n for n in nouns if n in named_entities]  # Filter nouns by those that are found by NRE
    print(email, nouns, sentence)
